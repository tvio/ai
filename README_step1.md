# Krok 1: ZÃ¡kladnÃ­ prÃ¡ce s Ollama modelem

Tento krok demonstruje, jak pouÅ¾Ã­vat lokÃ¡lnÃ­ AI model (Ollama) v Pythonu.

## Co se nauÄÃ­te

- âœ… Instalace a spuÅ¡tÄ›nÃ­ Ollama
- âœ… Komunikace s Ollama API z Pythonu
- âœ… Seznam dostupnÃ½ch modelÅ¯
- âœ… GenerovÃ¡nÃ­ textu pomocÃ­ lokÃ¡lnÃ­ho modelu

## Instalace

### 1. Instalace Ollama
StÃ¡hnÄ›te a nainstalujte Ollama z: https://ollama.ai/

### 2. StaÅ¾enÃ­ modelu
```bash
# StÃ¡hnÄ›te zÃ¡kladnÃ­ model
ollama pull llama2

# Nebo menÅ¡Ã­ model
ollama pull mistral
```

### 3. Python zÃ¡vislosti
```bash
pip install -r requirements_step1.txt
```

## PouÅ¾itÃ­

### SpuÅ¡tÄ›nÃ­ testu
```bash
python step1_ollama_basic.py
```

### Co skript dÄ›lÃ¡

1. **Test pÅ™ipojenÃ­** - OvÄ›Å™Ã­, Å¾e Ollama bÄ›Å¾Ã­
2. **Seznam modelÅ¯** - ZobrazÃ­ dostupnÃ© modely
3. **Test generovÃ¡nÃ­** - Vygeneruje text pomocÃ­ modelu

### PÅ™Ã­klad vÃ½stupu
```
ğŸ¤– Ollama - ZÃ¡kladnÃ­ test
========================================
1. Test pÅ™ipojenÃ­ k Ollama...
âœ… Ollama je dostupnÃ©!

2. DostupnÃ© modely:
   ğŸ“‹ llama2 (3.8 GB)

3. Test generovÃ¡nÃ­ textu...
   PouÅ¾Ã­vÃ¡m model: llama2
   Prompt: NapiÅ¡ krÃ¡tkou bÃ¡sniÄku o umÄ›lÃ© inteligenci.
   âœ… OdpovÄ›Ä:
   [GenerovanÃ½ text...]
```

## DalÅ¡Ã­ kroky

- **Krok 2**: PrÃ¡ce s PDF soubory
- **Krok 3**: VytvÃ¡Å™enÃ­ embeddingÅ¯
- **Krok 4**: UklÃ¡dÃ¡nÃ­ do databÃ¡ze

## Å˜eÅ¡enÃ­ problÃ©mÅ¯

### Ollama nenÃ­ dostupnÃ©
- Zkontrolujte, Å¾e Ollama je nainstalovÃ¡no
- SpusÅ¥te Ollama sluÅ¾bu
- Zkontrolujte port 11434

### Å½Ã¡dnÃ© modely
```bash
ollama pull llama2
```

### Chyba pÅ™ipojenÃ­
- Zkontrolujte firewall
- Zkontrolujte, Å¾e Ollama bÄ›Å¾Ã­ na localhost:11434 